{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"colab":{"name":"SimpleTransformers_MultiLabel_Pascal.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"90TsvpNc0GY6"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"r90PIB5b7XEi"},"outputs":[],"source":["!pip install transformers==2.5.1\n","!pip install simpletransformers==0.20.3\n","!pip install seqeval==0.0.12\n","!pip install torch==1.4+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html --no-cache-dir\n","!rm -rf .git\n","!rm -rf apex\n","!git clone https://github.com/NVIDIA/apex\n","!git checkout 494f8ab3fc1b0b26949a3bcbb2bcac78008d48c1\n","!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"0uvH53p_X-Gl"},"outputs":[],"source":["#This is the path where the files named CsvReader, HelperFunctions etc. are saved\n","cd /content/drive/My\\ Drive/Colab\\ Notebooks"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"OKs0E_mczgjr"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import copy\n","import sklearn\n","import csv\n","from sklearn.metrics import label_ranking_average_precision_score, label_ranking_loss, multilabel_confusion_matrix,classification_report, coverage_error, hamming_loss\n","\n","from CsvReader import ReadCsv\n","from HelperFunctions import ShuffleData, replace_all, ReplaceCategoriesWithIndex,ReplaceCategoriesWithIndexOneHot, OneHotEncodingForCategories, TransformDataIntoDataframe, getMetricsMulti, CalculateWeights\n","from TrainEvalModel import TrainModelForMultiLabel, EvalFromMultiLabelModel\n","from NonMLMethods import LogisticRegressionMulti\n","\n","#This is the path to csvs that should be read.\n","folderPath = '/content/drive/My Drive/Colab Notebooks Pascal/bert-etiki/etiki-data'\n","data, categories, tendencies = ReadCsv(folderPath, 'etikidata.csv','companies.csv', 'categories.csv','references.csv','tendencies.csv', 'topics.csv')\n","for k in range(1,3):\n","  for i in range(2,7):\n","    simpleTransformersData = data[:,[13,4,13]]\n","    baselineData = ReplaceCategoriesWithIndex(categories, data[:,[13,4,13]],False)\n","    \n","    baselineData = ShuffleData(baselineData)\n","    simpleTransformersData = ShuffleData(simpleTransformersData)  \n","\n","    singleLabelTrainData = np.array(OneHotEncodingForCategories(ReplaceCategoriesWithIndexOneHot(categories,np.array(simpleTransformersData[:int(len(simpleTransformersData)*0.7)]))))    \n","    multiLabelTestData = OneHotEncodingForCategories(ReplaceCategoriesWithIndex(categories,simpleTransformersData[int(len(simpleTransformersData)*0.7):],True))\n","\n","    train_single_df = TransformDataIntoDataframe(singleLabelTrainData)\n","    eval_multi_df = TransformDataIntoDataframe(multiLabelTestData)\n","\n","    eval_labels = np.array(eval_multi_df[\"label\"].tolist())\n","#------------------------------XLNET------------------------------\n","    algo = 'xlnet'\n","\n","    args = {'reprocess_input_data': True,\n","            'overwrite_output_dir': True,\n","            'num_train_epochs': i,\n","            'silent':True,\n","            'use_cached_eval_features': True,\n","            }\n","    model = TrainModelForMultiLabel(algo, 'xlnet-base-cased',train_single_df,5,args)\n","    # Evaluate the model\n","    result, model_outputs, wrong_predictions = EvalFromMultiLabelModel(model, eval_multi_df)\n","\n","    lrap = label_ranking_average_precision_score(eval_labels, model_outputs)\n","    lrl = label_ranking_loss(eval_labels, model_outputs)\n","    ce = coverage_error(eval_labels, model_outputs)\n","    \n","    with open('results/categories/'+str(i)+' epoch/'+algo+'-metrics.csv', 'a', newline='') as f:\n","      writer = csv.writer(f)\n","      writer.writerow([lrap,lrl,ce])\n","\n","    for j in range(1,10):\n","      threshold = 0.1*j\n","      op = []\n","      for output in model_outputs:\n","        li = output\n","        res = [1 if el > threshold else 0 for el in li]\n","        op.append(res)  \n","      out = np.array(op)\n","      cm = multilabel_confusion_matrix(eval_multi_labels, out)\n","      getMetricsMulti(cm, algo, 'categories/'+str(i)+' epoch/'+'{0:3.1f}'.format(0.1*j)+' threshold')\n","#------------------------------BERT------------------------------    \n","    algo = 'bert'\n","    args = {'reprocess_input_data': True,\n","            'overwrite_output_dir': True,\n","            'num_train_epochs': i,\n","            'silent':True,\n","            'use_cached_eval_features': True,\n","            }\n","    model = TrainModelForMultiLabel(algo, 'bert-base-cased',train_single_df,5,args)\n","    # Evaluate the model\n","    result, model_outputs, wrong_predictions = EvalFromMultiLabelModel(model, eval_multi_df)\n","\n","    lrap = label_ranking_average_precision_score(eval_labels, model_outputs)\n","    lrl = label_ranking_loss(eval_labels, model_outputs)\n","    ce = coverage_error(eval_labels, model_outputs)\n","    \n","    with open('results/categories/'+str(i)+' epoch/'+algo+'-metrics.csv', 'a', newline='') as f:\n","      writer = csv.writer(f)\n","      writer.writerow([lrap,lrl,ce])\n","\n","    for j in range(1,10):\n","      threshold = 0.1*j\n","      op = []\n","      for output in model_outputs:\n","        li = output\n","        res = [1 if el > threshold else 0 for el in li]\n","        op.append(res)  \n","      out = np.array(op)\n","      cm = multilabel_confusion_matrix(eval_multi_labels, out)\n","      getMetricsMulti(cm, algo, 'categories/'+str(i)+' epoch/'+'{0:3.1f}'.format(0.1*j)+' threshold')\n","#----------------------------RoBERTa------------------------------  \n","    algo = 'roberta'\n","    args = {'reprocess_input_data': True,\n","            'overwrite_output_dir': True,\n","            'num_train_epochs': i,\n","            'silent':True,\n","            'use_cached_eval_features': True,\n","            }\n","    model = TrainModelForMultiLabel(algo, 'roberta-base',train_single_df,5,args)\n","    # Evaluate the model\n","    result, model_outputs, wrong_predictions = EvalFromMultiLabelModel(model, eval_multi_df)\n","\n","    lrap = label_ranking_average_precision_score(eval_labels, model_outputs)\n","    lrl = label_ranking_loss(eval_labels, model_outputs)\n","    ce = coverage_error(eval_labels, model_outputs)\n","    \n","    with open('results/categories/'+str(i)+' epoch/'+algo+'-metrics.csv', 'a', newline='') as f:\n","      writer = csv.writer(f)\n","      writer.writerow([lrap,lrl,ce])\n","\n","    for j in range(1,10):\n","      threshold = 0.1*j\n","      op = []\n","      for output in model_outputs:\n","        li = output\n","        res = [1 if el > threshold else 0 for el in li]\n","        op.append(res)  \n","      out = np.array(op)\n","      cm = multilabel_confusion_matrix(eval_multi_labels, out)\n","      getMetricsMulti(cm, algo, 'categories/'+str(i)+' epoch/'+'{0:3.1f}'.format(0.1*j)+' threshold')\n","#--------------------------DistilBERT-----------------------------   \n","    algo = 'distilbert'\n","    args = {'reprocess_input_data': True,\n","            'overwrite_output_dir': True,\n","            'num_train_epochs': i,\n","            'silent':True,\n","            'use_cached_eval_features': True,\n","            }\n","    model = TrainModelForMultiLabel(algo, 'distilbert-base-cased',train_single_df,5,args)\n","    # Evaluate the model\n","    result, model_outputs, wrong_predictions = EvalFromMultiLabelModel(model, eval_multi_df)\n","\n","    lrap = label_ranking_average_precision_score(eval_labels, model_outputs)\n","    lrl = label_ranking_loss(eval_labels, model_outputs)\n","    ce = coverage_error(eval_labels, model_outputs)\n","    \n","    with open('results/categories/'+str(i)+' epoch/'+algo+'-metrics.csv', 'a', newline='') as f:\n","      writer = csv.writer(f)\n","      writer.writerow([lrap,lrl,ce])\n","\n","    for j in range(1,10):\n","      threshold = 0.1*j\n","      op = []\n","      for output in model_outputs:\n","        li = output\n","        res = [1 if el > threshold else 0 for el in li]\n","        op.append(res)  \n","      out = np.array(op)\n","      cm = multilabel_confusion_matrix(eval_multi_labels, out)\n","      getMetricsMulti(cm, algo, 'categories/'+str(i)+' epoch/'+'{0:3.1f}'.format(0.1*j)+' threshold')\n","#-----------------------Logistic Regression-----------------------\n","    algo = 'LogisticRegression'\n","\n","    baselineTrainData = ReplaceCategoriesWithIndexOneHot(categories,baselineData[:int(len(baselineData)*0.7)])\n","    baselineTestData = ReplaceCategoriesWithIndex(categories,baselineData[int(len(baselineData)*0.7):],True) \n","   \n","    model_outputs, label_test = LogisticRegressionMulti(baselineTrainData, baselineTestData)\n","    \n","    eval_labels = np.array(label_test)\n","  \n","    lrap = label_ranking_average_precision_score(eval_labels, model_outputs)\n","    lrl = label_ranking_loss(eval_labels, model_outputs)\n","    ce = coverage_error(eval_labels, model_outputs)\n","\n","    with open('results/categories/'+str(i)+' epoch/'+algo+'-metrics.csv', 'a', newline='') as f:\n","      writer = csv.writer(f)\n","      writer.writerow([lrap,lrl,ce])\n","\n","    for j in range(1,10):\n","      threshold = 0.1*j\n","      op = []\n","      for output in model_outputs:\n","        li = output\n","        res = [1 if el > threshold else 0 for el in li]\n","        op.append(res)  \n","      out = np.array(op)\n","      cm = multilabel_confusion_matrix(eval_multi_labels, out)\n","      getMetricsMulti(cm, algo, 'categories/'+str(i)+' epoch/'+'{0:3.1f}'.format(0.1*j)+' threshold')"]}]}