{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"colab":{"name":"MultiLabelClassification_Weighted_Labels.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"r90PIB5b7XEi","outputId":"3f929ca0-2929-4b4f-d870-7f5c35024c10","executionInfo":{"status":"ok","timestamp":1584465233466,"user_tz":-60,"elapsed":593700,"user":{"displayName":"Pascal Köchli","photoUrl":"https://lh3.googleusercontent.com/-1EfoILBbXtk/AAAAAAAAAAI/AAAAAAABHvM/9y6v_NyI6nM/s64/photo.jpg","userId":"05981628382544898026"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install transformers==2.5.1\n","!pip install simpletransformers==0.20.3\n","!pip install seqeval==0.0.12\n","!pip install torch==1.4+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html --no-cache-dir\n","!rm -rf .git\n","!rm -rf apex\n","!git clone https://github.com/NVIDIA/apex\n","!git checkout 494f8ab3fc1b0b26949a3bcbb2bcac78008d48c1\n","!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"90TsvpNc0GY6","outputId":"5f76a205-eced-4a03-f91b-35461cfca60d","executionInfo":{"status":"ok","timestamp":1584772109823,"user_tz":-60,"elapsed":813,"user":{"displayName":"Pascal Köchli","photoUrl":"https://lh3.googleusercontent.com/-1EfoILBbXtk/AAAAAAAAAAI/AAAAAAABHvM/9y6v_NyI6nM/s64/photo.jpg","userId":"05981628382544898026"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0uvH53p_X-Gl","colab":{}},"source":["cd /content/drive/My\\ Drive/Colab\\ Notebooks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OKs0E_mczgjr","colab":{}},"source":["import numpy as np\n","from sklearn.utils.class_weight import compute_class_weight\n","import pandas as pd\n","import torch\n","import copy\n","import sklearn\n","import csv\n","import tensorflow as tf\n","import datetime, os\n","from sklearn.metrics import label_ranking_average_precision_score, label_ranking_loss, multilabel_confusion_matrix,classification_report, coverage_error, hamming_loss\n","\n","from CsvReader import ReadCsv\n","from HelperFunctions import ShuffleData, replace_all, ReplaceCategoriesWithIndex,ReplaceCategoriesWithIndexOneHot, OneHotEncodingForCategories, TransformDataIntoDataframe, getMetricsMulti, CalculateWeights\n","from TrainEvalModel import TrainModelForMultiLabel, EvalFromMultiLabelModel\n","from NonMLMethods import LogisticRegressionMulti\n","\n","folderPath = '/content/drive/My Drive/Colab Notebooks Pascal/bert-etiki/etiki-data'\n","data, categories, tendencies = ReadCsv(folderPath, 'etikidata.csv','companies.csv', 'categories.csv','references.csv','tendencies.csv', 'topics.csv')\n","for k in range(1,3):\n","  for i in range(2,7):\n","    rawData = data[:,[13,4,13]]\n","    \n","    multiLabelData = OneHotEncodingForCategories(ReplaceCategoriesWithIndex(categories,rawData,True))\n","    np.random.shuffle(multiLabelData)   \n","\n","    trainData = multiLabelData[:int(len(multiLabelData)*0.7)]  \n","    testData =  multiLabelData[int(len(multiLabelData)*0.7):]\n","\n","    train_multi_df = TransformDataIntoDataframe(trainData)\n","    eval_multi_df = TransformDataIntoDataframe(testData)\n","\n","    rawSingleLabelData = data[:,[13,4,13]]\n","\n","    singleLabelTrainData = np.array(OneHotEncodingForCategories(ReplaceCategoriesWithIndexOneHot(categories,np.array(rawSingleLabelData[:int(len(rawSingleLabelData)*0.7)]))))    \n","    singleLabelTestData = OneHotEncodingForCategories(ReplaceCategoriesWithIndex(categories,rawSingleLabelData[int(len(rawSingleLabelData)*0.7):],True))\n","\n","    train_single_df = TransformDataIntoDataframe(singleLabelTrainData)\n","    eval_single_df = TransformDataIntoDataframe(singleLabelTestData)\n","\n","    eval_multi_labels = np.array(eval_multi_df[\"label\"].tolist())\n","    eval_single_labels = np.array(eval_single_df[\"label\"].tolist())\n","    \n","    distribution = np.array(OneHotEncodingForCategories(ReplaceCategoriesWithIndexOneHot(categories,np.array(rawSingleLabelData))))\n","    distribution_df = TransformDataIntoDataframe(distribution)\n","\n","    weightCalc = [np.array(x) for x in distribution_df[\"label\"]]\n","\n","    y_integers = np.argmax(weightCalc, axis=1)\n","\n","    class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers).tolist()\n","#------------------------------RoBERTa------------------------------\n","    algo = 'roberta'\n","\n","    args = {'reprocess_input_data': True,\n","            'overwrite_output_dir': True,\n","            'num_train_epochs': 6,\n","            'silent':True,\n","            'use_cached_eval_features': False,\n","            }\n","    model = TrainModelForMultiLabel(algo, 'roberta-base',train_multi_df,5,args,class_weights)\n","    # Evaluate the model\n","    result, model_outputs, wrong_predictions = EvalFromMultiLabelModel(model, eval_multi_df)\n","\n","    lrap = label_ranking_average_precision_score(eval_multi_labels, model_outputs)\n","    lrl = label_ranking_loss(eval_multi_labels, model_outputs)\n","    ce = coverage_error(eval_multi_labels, model_outputs)\n","    \n","    with open('results/categories/no-cached-weighted-combined/'+algo+'1-metrics.csv', 'a', newline='') as f:\n","      writer = csv.writer(f)\n","      writer.writerow([lrap,lrl,ce])\n","\n","    for j in range(1,10):\n","      threshold = 0.1*j\n","      op = []\n","      for output in model_outputs:\n","        li = output\n","        res = [1 if el > threshold else 0 for el in li]\n","        op.append(res)  \n","      out = np.array(op)\n","      cm = multilabel_confusion_matrix(eval_multi_labels, out)\n","      getMetricsMulti(cm,algo+'1', 'categories/no-cached-weighted-combined/'+'{0:3.1f}'.format(0.1*j)+' threshold')\n","\n","#----------------------------XLNet------------------------------  \n","    algo = 'xlnet'\n","    args = {'reprocess_input_data': True,\n","            'overwrite_output_dir': True,\n","            'num_train_epochs': 4,\n","            'silent':True,\n","            'use_cached_eval_features': False,\n","            }\n","    model = TrainModelForMultiLabel(algo, 'xlnet-base-cased',train_single_df,5,args,class_weights)\n","    # Evaluate the model\n","    result, model_outputs, wrong_predictions = EvalFromMultiLabelModel(model, eval_single_df)\n","\n","    lrap = label_ranking_average_precision_score(eval_single_labels, model_outputs)\n","    lrl = label_ranking_loss(eval_single_labels, model_outputs)\n","    ce = coverage_error(eval_single_labels, model_outputs)\n","    \n","    with open('results/categories/no-cached-weighted-not-combined/'+algo+'1-metrics.csv', 'a', newline='') as f:\n","      writer = csv.writer(f)\n","      writer.writerow([lrap,lrl,ce])\n","\n","    for j in range(1,10):\n","      threshold = 0.1*j\n","      op = []\n","      for output in model_outputs:\n","        li = output\n","        res = [1 if el > threshold else 0 for el in li]\n","        op.append(res)  \n","      out = np.array(op)\n","      cm = multilabel_confusion_matrix(eval_single_labels, out)\n","      getMetricsMulti(cm,algo+'1', 'categories/no-cached-weighted-not-combined/'+'{0:3.1f}'.format(0.1*j)+' threshold')"],"execution_count":null,"outputs":[]}]}