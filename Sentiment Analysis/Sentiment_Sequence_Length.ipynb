{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"colab":{"name":"StandardTestingRun_Sentiment_Sequence_Length.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"90TsvpNc0GY6","outputId":"a1faab2f-b91b-4cf7-e704-7741bfd9e4c9","colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"r90PIB5b7XEi","colab":{}},"source":["!pip install transformers==2.5.1\n","!pip install simpletransformers==0.20.3\n","!pip install seqeval==0.0.12\n","!pip install torch==1.4+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html --no-cache-dir\n","!rm -rf .git\n","!rm -rf apex\n","!git clone https://github.com/NVIDIA/apex\n","!git checkout 494f8ab3fc1b0b26949a3bcbb2bcac78008d48c1\n","!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nf7qSGtt7pw-","colab":{}},"source":["cd /content/drive/My\\ Drive/Colab\\ Notebooks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OKs0E_mczgjr","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import gc\n","import csv\n","\n","from CsvReader import ReadCsv\n","from HelperFunctions import ShuffleData, replace_all, ReplaceSentimentsWithIndexes, SplitArticlesIntoSentiments, getMetrics, TransformDataIntoDataframe, CalculateWeights\n","from TrainEvalModel import TrainModelForMultiClass, EvalFromModel\n","\n","path = '/content/drive/My Drive/Colab Notebooks Pascal/bert-etiki/etiki-data'\n","data, categories, tendencies = ReadCsv(path, 'test.csv','companies.csv', 'categories.csv','references.csv','tendencies.csv', 'topics.csv')\n","sentimentData = ReplaceSentimentsWithIndexes(data[:,[0,7,13]])\n","labels = np.unique(sentimentData[:,1])\n","weights = CalculateWeights(labels,sentimentData)\n","\n","for j in range(2,6):\n","  positiveArticles, negativeArticles, controversialArticles = SplitArticlesIntoSentiments(sentimentData)\n","  positiveArticles = ShuffleData(positiveArticles)\n","  negativeArticles = ShuffleData(negativeArticles)\n","  controversialArticles = ShuffleData(controversialArticles)\n","  trainData = np.vstack((positiveArticles[:int(len(positiveArticles)*0.7)],controversialArticles[:int(len(controversialArticles)*0.7)],negativeArticles[:int(len(negativeArticles)*0.7)]))\n","  testData = np.vstack((positiveArticles[int(len(positiveArticles)*0.7):],controversialArticles[int(len(controversialArticles)*0.7):],negativeArticles[int(len(negativeArticles)*0.7):]))\n","  train_df = TransformDataIntoDataframe(trainData)\n","  eval_df = TransformDataIntoDataframe(testData)\n","#-----------------------------128------------------------------\n","  algo = 'xlnet'        \n","  args = {'reprocess_input_data': True,\n","            'overwrite_output_dir': True,\n","            'num_train_epochs':j ,\n","            'silent':True,\n","            'use_cached_eval_features':True, \n","            'max_seq_length':128\n","            }\n","  model = TrainModelForMultiClass(algo, 'xlnet-base-cased',train_df,3,args, weights)\n","  result, model_outputs, wrong_predictions = EvalFromModel(model,eval_df)\n","  with open('results/'+str(j)+'epoch/'+algo+'-mcc.csv', 'a', newline='') as f:\n","    writer = csv.writer(f)\n","    writer.writerow([result['mcc'],result[\"acc\"],result[\"eval_loss\"]])\n","  getMetrics(result[\"matr\"],3,str(j)+'epoch/'+algo) \n","#-----------------------------256------------------------------\n","  algo = 'xlnet'        \n","  args = {'reprocess_input_data': True,\n","            'overwrite_output_dir': True,\n","            'num_train_epochs':j ,\n","            'silent':True,\n","            'use_cached_eval_features':True, \n","            'max_seq_length':256\n","            }\n","  model = TrainModelForMultiClass(algo, 'xlnet-base-cased',train_df,3,args, weights)\n","  result, model_outputs, wrong_predictions = EvalFromModel(model,eval_df)\n","  with open('results/'+str(j)+'epoch/'+algo+'-mcc.csv', 'a', newline='') as f:\n","    writer = csv.writer(f)\n","    writer.writerow([result['mcc'],result[\"acc\"],result[\"eval_loss\"]])\n","  getMetrics(result[\"matr\"],3,str(j)+'epoch/'+algo)\n","  #-----------------------------512------------------------------\n","  algo = 'xlnet'        \n","  args = {'reprocess_input_data': True,\n","            'overwrite_output_dir': True,\n","            'num_train_epochs':j ,\n","            'silent':True,\n","            'use_cached_eval_features':True, \n","            'max_seq_length':512\n","            }\n","  model = TrainModelForMultiClass(algo, 'xlnet-base-cased',train_df,3,args, weights)\n","  result, model_outputs, wrong_predictions = EvalFromModel(model,eval_df)\n","  with open('results/'+str(j)+'epoch/'+algo+'-mcc.csv', 'a', newline='') as f:\n","    writer = csv.writer(f)\n","    writer.writerow([result['mcc'],result[\"acc\"],result[\"eval_loss\"]])\n","  getMetrics(result[\"matr\"],3,str(j)+'epoch/'+algo)"],"execution_count":null,"outputs":[]}]}