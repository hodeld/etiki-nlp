{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"colab":{"name":"SimpleTransformers_MultiLabel_Pascal.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"-sSBy7YWbfN6"},"outputs":[],"source":["!pip install tensorboardx"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"r90PIB5b7XEi"},"outputs":[],"source":["!pip install transformers==2.5.1\n","!pip install simpletransformers==0.20.3\n","!pip install seqeval==0.0.12\n","\n","!pip install torch==1.4+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html --no-cache-dir\n","#!pip install torch==1.3.0+cu100 torchvision==0.4.1+cu100 -f https://download.pytorch.org/whl/torch_stable.html --no-cache-dir\n","#!pip install torch==1.4.0 torchvision==0.4.0 -f https://download.pytorch.org/whl/cu100/torch_stable.html --no-cache-dir\n","!rm -rf .git\n","!rm -rf apex\n","!git clone https://github.com/NVIDIA/apex\n","!git checkout 494f8ab3fc1b0b26949a3bcbb2bcac78008d48c1\n","!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"90TsvpNc0GY6"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"0uvH53p_X-Gl"},"outputs":[],"source":["cd /content/drive/My\\ Drive/Colab\\ Notebooks"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"edYAGsWh1SHu"},"outputs":[],"source":["\n","#import subprocess\n","#subprocess.call(['./installpackages.sh'])"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"OKs0E_mczgjr"},"outputs":[],"source":["import numpy as np\n","from sklearn.utils.class_weight import compute_class_weight\n","import pandas as pd\n","import torch\n","import copy\n","import sklearn\n","import csv\n","import tensorflow as tf\n","import datetime, os\n","from sklearn.metrics import label_ranking_average_precision_score, label_ranking_loss, multilabel_confusion_matrix,classification_report, coverage_error, hamming_loss\n","\n","from CsvReader import ReadCsv\n","from HelperFunctions import ShuffleData, replace_all, ReplaceCategoriesWithIndex,ReplaceCategoriesWithIndexOneHot, OneHotEncodingForCategories, TransformDataIntoDataframe, getMetricsMulti, CalculateWeights\n","from TrainEvalModel import TrainModelForMultiLabel, EvalFromModel\n","from NonMLMethods import LogisticRegressionMulti\n","\n","folderPath = '/content/drive/My Drive/Colab Notebooks Pascal/bert-etiki/etiki-data'\n","data, categories, tendencies = ReadCsv(folderPath, 'test.csv','companies.csv', 'categories.csv','references.csv','tendencies.csv', 'topics.csv')\n","for k in range(1,3):\n","  for i in range(2,7):\n","    categoryData = data[:,[0,4,13]]\n","    baselineData = ReplaceCategoriesWithIndex(categories, data[:,[0,4,13]],False)\n","    \n","    baselineData = ShuffleData(baselineData)\n","    categoryData = ShuffleData(categoryData)   \n","\n","    trainData = np.array(OneHotEncodingForCategories(ReplaceCategoriesWithIndexOneHot(categories,np.array(categoryData[:int(len(categoryData)*0.7)]))))    \n","    testData = OneHotEncodingForCategories(ReplaceCategoriesWithIndex(categories,categoryData[int(len(categoryData)*0.7):],True))\n","\n","    train_df = TransformDataIntoDataframe(trainData)\n","    eval_df = TransformDataIntoDataframe(testData)\n","\n","    eval_labels = np.array(eval_df[\"label\"].tolist())\n","#------------------------------XLNET------------------------------\n","    algo = 'xlnet'\n","\n","    args = {'reprocess_input_data': True,\n","            'overwrite_output_dir': True,\n","            'num_train_epochs': i,\n","            'silent':True,\n","            'use_cached_eval_features': True,\n","            'save_steps':5,\n","            'logging_steps': 5,\n","            }\n","    model = TrainModelForMultiLabel(algo, 'xlnet-base-cased',train_df,5,args)\n","    # Evaluate the model\n","    result, model_outputs, wrong_predictions = EvalFromMultiLabelModel(model, eval_df)\n","\n","    lrap = label_ranking_average_precision_score(eval_labels, model_outputs)\n","    lrl = label_ranking_loss(eval_labels, model_outputs)\n","    ce = coverage_error(eval_labels, model_outputs)\n","    \n","    with open('results/categories/cached_features/'+str(i)+' epoch/'+algo+'-metrics.csv', 'a', newline='') as f:\n","      writer = csv.writer(f)\n","      writer.writerow([lrap,lrl,ce])\n","\n","    for j in range(1,10):\n","      threshold = 0.1*j\n","      op = []\n","      for output in model_outputs:\n","        li = output\n","        res = [1 if el > threshold else 0 for el in li]\n","        op.append(res)  \n","      out = np.array(op)\n","      cm = multilabel_confusion_matrix(eval_labels, out)\n","      getMetricsMulti(cm,algo, 'categories/cached_features/'+str(i)+' epoch/'+'{0:3.1f}'.format(0.1*j)+' threshold')\n","#------------------------------BERT------------------------------    \n","    algo = 'bert'\n","    args = {'reprocess_input_data': True,\n","            'overwrite_output_dir': True,\n","            'num_train_epochs': i,\n","            'silent':True,\n","            'use_cached_eval_features': True,\n","            'save_steps':5,\n","            'logging_steps': 5,\n","            }\n","    model = TrainModelForMultiLabel(algo, 'bert-base-cased',train_df,5,args)\n","    # Evaluate the model\n","    result, model_outputs, wrong_predictions = EvalFromMultiLabelModel(model, eval_df)\n","\n","    lrap = label_ranking_average_precision_score(eval_labels, model_outputs)\n","    lrl = label_ranking_loss(eval_labels, model_outputs)\n","    ce = coverage_error(eval_labels, model_outputs)\n","    \n","    with open('results/categories/cached_features/'+str(i)+' epoch/'+algo+'-metrics.csv', 'a', newline='') as f:\n","      writer = csv.writer(f)\n","      writer.writerow([lrap,lrl,ce])\n","\n","    for j in range(1,10):\n","      threshold = 0.1*j\n","      op = []\n","      for output in model_outputs:\n","        li = output\n","        res = [1 if el > threshold else 0 for el in li]\n","        op.append(res)  \n","      out = np.array(op)\n","      cm = multilabel_confusion_matrix(eval_labels, out)\n","      getMetricsMulti(cm,algo, 'categories/cached_features/'+str(i)+' epoch/'+'{0:3.1f}'.format(0.1*j)+' threshold')\n","#----------------------------RoBERTa------------------------------  \n","    algo = 'roberta'\n","    args = {'reprocess_input_data': True,\n","            'overwrite_output_dir': True,\n","            'num_train_epochs': i,\n","            'silent':True,\n","            'use_cached_eval_features': True,\n","            'save_steps':5,\n","            'logging_steps': 5,\n","            }\n","    model = TrainModelForMultiLabel(algo, 'roberta-base',train_df,5,args)\n","    # Evaluate the model\n","    result, model_outputs, wrong_predictions = EvalFromMultiLabelModel(model, eval_df)\n","\n","    lrap = label_ranking_average_precision_score(eval_labels, model_outputs)\n","    lrl = label_ranking_loss(eval_labels, model_outputs)\n","    ce = coverage_error(eval_labels, model_outputs)\n","    \n","    with open('results/categories/cached_features/'+str(i)+' epoch/'+algo+'-metrics.csv', 'a', newline='') as f:\n","      writer = csv.writer(f)\n","      writer.writerow([lrap,lrl,ce])\n","\n","    for j in range(1,10):\n","      threshold = 0.1*j\n","      op = []\n","      for output in model_outputs:\n","        li = output\n","        res = [1 if el > threshold else 0 for el in li]\n","        op.append(res)  \n","      out = np.array(op)\n","      cm = multilabel_confusion_matrix(eval_labels, out)\n","      getMetricsMulti(cm,algo, 'categories/cached_features/'+str(i)+' epoch/'+'{0:3.1f}'.format(0.1*j)+' threshold')\n","#----------------------------RoBERTa------------------------------  \n","    algo = 'distilbert'\n","    args = {'reprocess_input_data': True,\n","            'overwrite_output_dir': True,\n","            'num_train_epochs': i,\n","            'silent':True,\n","            'use_cached_eval_features': True,\n","            'save_steps':5,\n","            'logging_steps': 5,\n","            }\n","    model = TrainModelForMultiLabel(algo, 'distilbert-base-cased',train_df,5,args)\n","    # Evaluate the model\n","    result, model_outputs, wrong_predictions = EvalFromMultiLabelModel(model, eval_df)\n","\n","    lrap = label_ranking_average_precision_score(eval_labels, model_outputs)\n","    lrl = label_ranking_loss(eval_labels, model_outputs)\n","    ce = coverage_error(eval_labels, model_outputs)\n","    \n","    with open('results/categories/cached_features/'+str(i)+' epoch/'+algo+'-metrics.csv', 'a', newline='') as f:\n","      writer = csv.writer(f)\n","      writer.writerow([lrap,lrl,ce])\n","\n","    for j in range(1,10):\n","      threshold = 0.1*j\n","      op = []\n","      for output in model_outputs:\n","        li = output\n","        res = [1 if el > threshold else 0 for el in li]\n","        op.append(res)  \n","      out = np.array(op)\n","      cm = multilabel_confusion_matrix(eval_labels, out)\n","      getMetricsMulti(cm,algo, 'categories/cached_features/'+str(i)+' epoch/'+'{0:3.1f}'.format(0.1*j)+' threshold')\n","#-----------------------Logistic Regression-----------------------\n","    algo = 'LogisticRegression'\n","\n","    trainDataBL = np.array(baselineData[:int(len(baselineData)*0.7)])\n","    testDataBL = baselineData[int(len(baselineData)*0.7):] \n","    train_dfBL = TransformDataIntoDataframe(trainDataBL)\n","    eval_dfBL = TransformDataIntoDataframe(testDataBL)\n","    newArray = []\n","    for entry in testDataBL:\n","      newEntry = [entry[0],list(entry[1]), entry[2]]\n","      newArray.append(newEntry)\n","    cm_testDataBL = OneHotEncodingForCategories(np.array(newArray))\n","    cm_testData_dfBL = TransformDataIntoDataframe(cm_testDataBL)\n","\n","    prediction = LogisticRegressionMulti(train_dfBL, eval_dfBL)\n","    \n","    eval_labels = np.array(cm_testData_dfBL[\"label\"].tolist())\n","  \n","    lrap = label_ranking_average_precision_score(eval_labels, prediction)\n","    lrl = label_ranking_loss(eval_labels, prediction)\n","    ce = coverage_error(eval_labels, prediction)\n","\n","    with open('results/categories/cached_features/'+str(i)+' epoch/'+algo+'-metrics.csv', 'a', newline='') as f:\n","      writer = csv.writer(f)\n","      writer.writerow([lrap,lrl,ce])\n","\n","    for j in range(1,10):\n","      threshold = 0.1*j\n","      op = []\n","      for output in prediction:\n","        li = output\n","        res = [1 if el > threshold else 0 for el in li]\n","        op.append(res)  \n","      out = np.array(op)\n","      cm = multilabel_confusion_matrix(eval_labels, out)\n","      getMetricsMulti(cm,algo, 'categories/cached_features/'+str(i)+' epoch/'+'{0:3.1f}'.format(0.1*j)+' threshold')"]}]}