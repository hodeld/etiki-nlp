# -*- coding: utf-8 -*-
"""StandardTestingRun.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PQmpxWs-SMRdvZ8prTOoFPi3fB7qddMI
"""

!pip install transformers
!pip install seqeval
!pip install tensorboardx
!pip install torchvision==0.4.0 -f https://download.pytorch.org/whl/cu100/torch_stable.html --no-cache-dir
!rm -rf .git
!rm -rf apex
!git clone https://github.com/NVIDIA/apex
!pip install -v --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./apex
!pip3 install simpletransformers
!pip install Afinn

from google.colab import drive
drive.mount("/content/drive")

cd /content/drive/My\ Drive/Colab\ Notebooks

import numpy as np
import pandas as pd
import torch
import gc

from CsvReader import ReadCsv
from HelperFunctions import ShuffleData, replace_all, ReplaceSentimentsWithIndexes, SplitArticlesIntoSentiments, getMetrics, TransformDataIntoDataframe, CalculateWeights
from TrainEvalModel import TrainModelForMultiClass, EvalFromModel

data, categories, tendencies = ReadCsv('/content/drive/My Drive/Colab Notebooks Pascal/bert-etiki/etiki-data','test.csv','companies.csv', 'categories.csv','references.csv','tendencies.csv', 'topics.csv')
sentimentData = ReplaceSentimentsWithIndexes(data[:,[0,7,13]])
labels = np.unique(sentimentData[:,1])
weights = CalculateWeights(labels,sentimentData)

positiveArticles, negativeArticles, controversialArticles = SplitArticlesIntoSentiments(sentimentData)
positiveArticles = ShuffleData(positiveArticles)
negativeArticles = ShuffleData(negativeArticles)
controversialArticles = ShuffleData(controversialArticles)

trainData = np.vstack((positiveArticles[:int(len(positiveArticles)*0.7)],controversialArticles[:int(len(controversialArticles)*0.7)],negativeArticles[:int(len(negativeArticles)*0.7)]))
testData = np.vstack((positiveArticles[int(len(positiveArticles)*0.7):],controversialArticles[int(len(controversialArticles)*0.7):],negativeArticles[int(len(negativeArticles)*0.7):]))
train_df = TransformDataIntoDataframe(trainData)
eval_df = TransformDataIntoDataframe(testData)

for i in range(2,7):
  algo = 'xlnet'
  args = {'reprocess_input_data': True,
          'overwrite_output_dir': True,
          'num_train_epochs': i,
          'silent':True
          }

  model = TrainModelForMultiClass('xlnet', 'xlnet-base-cased',train_df,3,args,[0.3333,0.3333,0.3334])
  result, model_outputs, wrong_predictions = EvalFromModel(model,eval_df)
  getMetrics(result["matr"],3,algo+'-noweight-' + str(i))
  torch.cuda.empty_cache()
  del model
  del result
  del model_outputs
  del wrong_predictions
  torch.cuda.empty_cache()
  gc.collect()

  args = {'reprocess_input_data': True,
          'overwrite_output_dir': True,
          'num_train_epochs': i,
          'silent':True
          }

  model = TrainModelForMultiClass('xlnet', 'xlnet-base-cased',train_df,3,args, weights)
  result, model_outputs, wrong_predictions = EvalFromModel(model,eval_df)
  getMetrics(result["matr"],3,algo+'-weight-' + str(i))
  torch.cuda.empty_cache()
  del model
  del result
  del model_outputs
  del wrong_predictions
  torch.cuda.empty_cache()
  gc.collect()  

  """
  xlNetModel = TrainModelForMultiClass('xlnet', 'xlnet-base-cased', train_df,3,args)
  xlResult, xl_model_outputs, xl_wrong_predictions = EvalFromModel(xlNetModel,eval_df)
  getMetrics(xlResult["matr"],3,"XLNet-"+str(i))
  torch.cuda.empty_cache()
  del xlNetModel
  del xlResult
  del xl_model_outputs
  del xl_wrong_predictions
  torch.cuda.empty_cache()
  gc.collect() 
  """

